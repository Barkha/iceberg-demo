{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 — Time Travel\n",
    "\n",
    "Every write to an Iceberg table creates an immutable **snapshot**. This means you can:\n",
    "1. Query data as it existed at any point in time\n",
    "2. List all snapshots and their metadata\n",
    "3. Roll back to a previous version\n",
    "\n",
    "This is a game-changer for debugging, auditing, and recovering from mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"IcebergDemo\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.1\")\n",
    "    .config(\"spark.sql.catalog.demo\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.demo.type\", \"hadoop\")\n",
    "    .config(\"spark.sql.catalog.demo.warehouse\", \"../warehouse\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "print(\"Spark + Iceberg ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. List All Snapshots\n",
    "\n",
    "Iceberg exposes metadata tables that you can query with SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots_df = spark.sql(\"\"\"\n",
    "    SELECT snapshot_id, committed_at, operation, summary\n",
    "    FROM demo.ecommerce.orders.snapshots\n",
    "    ORDER BY committed_at\n",
    "\"\"\")\n",
    "\n",
    "snapshots_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first snapshot ID for time-travel queries below\n",
    "snapshot_ids = [row.snapshot_id for row in snapshots_df.collect()]\n",
    "first_snapshot_id = snapshot_ids[0]\n",
    "print(f\"First snapshot ID: {first_snapshot_id}\")\n",
    "print(f\"Total snapshots: {len(snapshot_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query a Previous Snapshot\n",
    "\n",
    "Use `VERSION AS OF <snapshot_id>` to read data as it was at a specific snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data at the FIRST snapshot (snapshot_id = {first_snapshot_id}):\")\n",
    "print(\"This was right after the initial INSERT in notebook 01.\")\n",
    "print()\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT * FROM demo.ecommerce.orders\n",
    "    VERSION AS OF {first_snapshot_id}\n",
    "    ORDER BY order_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data at the CURRENT (latest) snapshot:\")\n",
    "print()\n",
    "\n",
    "spark.sql(\"SELECT * FROM demo.ecommerce.orders ORDER BY order_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View the History Table\n",
    "\n",
    "The `history` metadata table shows which snapshot was current at each point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * FROM demo.ecommerce.orders.history\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rollback to a Previous Snapshot\n",
    "\n",
    "Made a mistake? Roll back the table to any previous snapshot.\n",
    "\n",
    "This is a metadata-only operation — no data files are rewritten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before rollback:\")\n",
    "spark.sql(\"SELECT COUNT(*) AS row_count FROM demo.ecommerce.orders\").show()\n",
    "\n",
    "# Roll back to the first snapshot\n",
    "spark.sql(f\"\"\"\n",
    "    CALL demo.system.rollback_to_snapshot('ecommerce.orders', {first_snapshot_id})\n",
    "\"\"\")\n",
    "\n",
    "print(f\"After rollback to snapshot {first_snapshot_id}:\")\n",
    "spark.sql(\"SELECT * FROM demo.ecommerce.orders ORDER BY order_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Restore the Latest State\n",
    "\n",
    "Let's re-insert data so the next notebooks have something to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll forward to the latest snapshot\n",
    "last_snapshot_id = snapshot_ids[-1]\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CALL demo.system.rollback_to_snapshot('ecommerce.orders', {last_snapshot_id})\n",
    "\"\"\")\n",
    "\n",
    "print(\"Restored to latest snapshot.\")\n",
    "spark.sql(\"SELECT * FROM demo.ecommerce.orders ORDER BY order_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "| Feature              | How it works                                    |\n",
    "|----------------------|-------------------------------------------------|\n",
    "| Snapshot history     | Every write creates an immutable snapshot        |\n",
    "| Time-travel queries  | `VERSION AS OF <snapshot_id>`                    |\n",
    "| Metadata tables      | `.snapshots`, `.history`, `.files`, etc.         |\n",
    "| Rollback             | Metadata-only — instant, no data rewrite         |\n",
    "\n",
    "**Next up:** Schema evolution in notebook 04!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
